{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Recursive Karcher Expectation Estimator.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NcOpFighczd"
      },
      "source": [
        "##**Recursive Karcher Expectation Estimator**\n",
        "\n",
        "Following Notebooks Implements Estimator for Mean of Symmetric Positive Matrices. In first section Motivation of the problem is given. In second section Naive Implementation of Estimator is given and is shown to be extremely slow by profilling. Thereafter two efficient implementations are suggested that obtains about **110X** and **140X** Improvement in Efficiency. Also,  **4X** improvement is obtained over current implementaion in `geomstats` in fundamental task of computing GL-invariant distance  between batches of SPD matrices. In third section, A detailed Ablation study is conducted"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ttt1wJePllVi"
      },
      "source": [
        "**THE PROBLEM**\n",
        "\n",
        "Consider a manifold of Symmetric Positive Definite (SPD) Matrices of dimension $n$ denoted as $\\text{Sym}_{+}^{n}$. Assume that $X : \\Omega \\rightarrow \\text{Sym}_{+}^{n} $ is SPD valued random variable then its Karcher Expectation is defined as \n",
        "\n",
        "$$\\mathbb{KE}X = \\min_{\\mu^{*} \\in \\text{Sym}_{+}^d} \\int_{\\Omega} d^{2}(\\mu^{*} ,X) d \\omega $$ We are interested in finding the sample mean given $N$ SPD matrices  under GL-invariant metric (or Rao-Fisher Metric) which is defined as \n",
        "\n",
        "$$d^{2}(X,Y) = \\text{Tr} \\left[ \\text{Log}(X^{-1}Y) \\right]$$ Under GL-invariant there is unique solution  but not in closed form so we have to resort numerical optimization. As alternative this notebook tests recursive estimator and shows how to implement efficiently. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r9Aeu5S8suBf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c512ad1-8d3f-4d74-b5a0-291ebaeae8cb"
      },
      "source": [
        "!pip3 install geomstats\n",
        "!pip3 install line_profiler\n",
        "!pip3 install tqdm\n",
        "!pip3 install seaborn\n",
        "%load_ext line_profiler"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: geomstats in /usr/local/lib/python3.7/dist-packages (2.2.2)\n",
            "Requirement already satisfied: joblib==0.14.1 in /usr/local/lib/python3.7/dist-packages (from geomstats) (0.14.1)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from geomstats) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.7/dist-packages (from geomstats) (1.19.5)\n",
            "Requirement already satisfied: autograd==1.3 in /usr/local/lib/python3.7/dist-packages (from geomstats) (1.3)\n",
            "Requirement already satisfied: scikit-learn>=0.22.1 in /usr/local/lib/python3.7/dist-packages (from geomstats) (0.22.2.post1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from geomstats) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from geomstats) (3.2.2)\n",
            "Requirement already satisfied: jupyter in /usr/local/lib/python3.7/dist-packages (from geomstats) (1.0.0)\n",
            "Requirement already satisfied: future>=0.15.2 in /usr/local/lib/python3.7/dist-packages (from autograd==1.3->geomstats) (0.16.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->geomstats) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->geomstats) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->geomstats) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->geomstats) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->geomstats) (0.10.0)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (5.2.0)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (4.10.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (5.3.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (5.6.1)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (7.6.3)\n",
            "Requirement already satisfied: qtconsole in /usr/local/lib/python3.7/dist-packages (from jupyter->geomstats) (5.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->geomstats) (1.15.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->geomstats) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->geomstats) (1.0.18)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->geomstats) (5.3.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from jupyter-console->jupyter->geomstats) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->geomstats) (5.0.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->geomstats) (5.1.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (0.9.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (2.11.3)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (5.1.3)\n",
            "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (4.7.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (0.2.0)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->geomstats) (1.5.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (1.4.3)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (0.8.4)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (3.3.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->geomstats) (0.3)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->geomstats) (3.5.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->geomstats) (1.0.0)\n",
            "Requirement already satisfied: qtpy in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->geomstats) (1.9.0)\n",
            "Requirement already satisfied: pyzmq>=17.1 in /usr/local/lib/python3.7/dist-packages (from qtconsole->jupyter->geomstats) (22.0.3)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->geomstats) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->geomstats) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->geomstats) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->geomstats) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->jupyter-console->jupyter->geomstats) (56.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.0->jupyter-console->jupyter->geomstats) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->geomstats) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->geomstats) (1.1.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->geomstats) (2.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->geomstats) (20.9)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->geomstats) (0.5.1)\n",
            "Requirement already satisfied: line_profiler in /usr/local/lib/python3.7/dist-packages (3.2.6)\n",
            "Requirement already satisfied: IPython>=0.13; python_version >= \"3.7\" in /usr/local/lib/python3.7/dist-packages (from line_profiler) (5.5.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (56.0.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (5.0.5)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (2.6.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (4.8.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython>=0.13; python_version >= \"3.7\"->line_profiler) (1.0.18)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython>=0.13; python_version >= \"3.7\"->line_profiler) (1.15.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (0.11.1)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.1.5)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.19.5)\n",
            "Requirement already satisfied: matplotlib>=2.2 in /usr/local/lib/python3.7/dist-packages (from seaborn) (3.2.2)\n",
            "Requirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from seaborn) (1.4.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.23->seaborn) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n",
            "The line_profiler extension is already loaded. To reload it, use:\n",
            "  %reload_ext line_profiler\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQJuP6kHvlPr"
      },
      "source": [
        "import numpy as np\n",
        "import geomstats.geometry.spd_matrices as spd\n",
        "import geomstats.backend as gs\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from scipy.linalg import fractional_matrix_power\n",
        "from geomstats.geometry.spd_matrices import SPDMetricAffine\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF_ldLbcvtlJ"
      },
      "source": [
        "def logm(spd_mats):\n",
        "  \"\"\"\n",
        "  could be two_dim,three_dim,four_dim\n",
        "  spd_matrix : [n,n] , [p,n,n] , [p,N,n,n]\n",
        "\n",
        "  Returns:\n",
        "  ------------\n",
        "  return logm_m\n",
        "  \"\"\"\n",
        "\n",
        "  n = spd_mats.shape[-1]\n",
        "  SPDmanifold = spd.SPDMatrices(n)\n",
        "  if spd_mats.ndim == 2 or spd_mats.ndim == 3 :\n",
        "    log_m = SPDmanifold.logm(spd_mats)\n",
        "  elif spd_mats.ndim == 4:\n",
        "    p,N = spd_mats.shape[0] , spd_mats.shape[1]\n",
        "    log_m = SPDmanifold.logm(spd_mats.reshape(-1,n,n)).reshape(p,N,n,n) \n",
        "  else :\n",
        "    print(\"error exception!!!\")  \n",
        "    log_m = None\n",
        "  \n",
        "  return log_m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AHCZpo8O6_4g"
      },
      "source": [
        "def expm(spd_mats):\n",
        "  \"\"\"\n",
        "  could be two_dim,three_dim,four_dim\n",
        "  spd_matrix : [n,n] , [p,n,n] , [p,N,n,n]\n",
        "\n",
        "  Returns:\n",
        "  ------------\n",
        "  return exp_m\n",
        "  \"\"\"\n",
        "\n",
        "  n = spd_mats.shape[-1]\n",
        "  SPDmanifold = spd.SPDMatrices(n)\n",
        "  if spd_mats.ndim == 2 or spd_mats.ndim == 3 :\n",
        "    exp_m = SPDmanifold.expm(spd_mats)\n",
        "  elif spd_mats.ndim == 4:\n",
        "    p,N = spd_mats.shape[0] , spd_mats.shape[1]\n",
        "    exp_m = (SPDmanifold.expm(spd_mats.reshape(-1,n,n))).reshape(p,N,n,n) \n",
        "  else :\n",
        "    print(\"error exception!!!\")  \n",
        "    exp_m = None\n",
        "  \n",
        "  return exp_m"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5bPbTYZvyMn"
      },
      "source": [
        "#isometric embedding of SPD(n) matrix in R^{n(n+1)/2}\n",
        "\n",
        "def SPD_to_Euclidean(spd_matrix):\n",
        "  \"\"\"\n",
        "    spd_matrix : Symmetric positive definite matrix\n",
        "\n",
        "    Returns: numpy array of dimension (n(n+1)/2,)\n",
        "    Isometric Embedding of n x n Symmetric positive definite matrix in R^{n(n+1)/2} \n",
        "  \"\"\" \n",
        "  n = spd_matrix.shape[0]\n",
        "  sym_matrix = logm(spd_matrix)\n",
        "  diag = np.diag(sym_matrix)\n",
        "  uppTri = np.sqrt(2)*sym_matrix[np.triu_indices_from(sym_matrix, k=1)]\n",
        "  vecd =  gs.hstack((diag,uppTri))\n",
        "  return vecd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35gLcS9Hv3zn"
      },
      "source": [
        "#isometric embedding of R^{n(n+1)/2} matrix in SPD(n)\n",
        "\n",
        "def Euclidean_to_SPD(euclidean_vec):\n",
        "  \"\"\"\n",
        "    eucliden_vec : Euclidean column vector\n",
        "\n",
        "    Returns: [n,n]\n",
        "    Isometric Embedding of R^{n(n+1)/2} into n x n symmetric definite matrix\n",
        "  \"\"\"\n",
        "  q = euclidean_vec.shape[0]\n",
        "  n = (int)((- 1 + np.sqrt(1+8*q))/2)\n",
        "  diag = euclidean_vec[:n]\n",
        "  off_diag = euclidean_vec[n:]/(np.sqrt(2))\n",
        "  sym_matrix = np.diag(diag)\n",
        "  i,j = np.triu_indices_from(sym_matrix, k=1)\n",
        "  sym_matrix[i,j] = off_diag\n",
        "  sym_matrix[j,i] = off_diag\n",
        "  spd_matrix = expm(sym_matrix)\n",
        "  return spd_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uV0eX5cv9IS"
      },
      "source": [
        "#samples SPD matrices according to log-normal distribution with mean 'mean' and covariance 'cov'\n",
        "\n",
        "def log_normal_sampling(mean,cov,sample_size=1):\n",
        "  \"\"\"\n",
        "    mean : SPD matrix n x n\n",
        "    cov  : SPD matrix n(n+1)/2 x n(n+1)/2 \n",
        "\n",
        "    Returns:\n",
        "    list of SPD matrices of size 'sample_size' \n",
        "\n",
        "    TODO\n",
        "    vectorize conversion part\n",
        "  \"\"\"\n",
        " \n",
        "  mean_euclidean = SPD_to_Euclidean(mean)\n",
        "  samples_spd = []\n",
        "  manifold = spd.SPDMatrices(mean.shape[0])\n",
        "  samples_euclidean = np.random.multivariate_normal(mean_euclidean, cov, sample_size)\n",
        "  for i in range(sample_size):\n",
        "    sample_spd = Euclidean_to_SPD(samples_euclidean[i])\n",
        "    samples_spd.append(sample_spd)\n",
        "    \n",
        "  samples_spd = np.array(samples_spd) \n",
        "  return samples_spd if (gs.all(manifold.belongs(samples_spd))) else None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bcGhLqdNwGT9"
      },
      "source": [
        "def synthetic_data(mean,cov,sample_size):\n",
        "  \"\"\"\n",
        "  mean : [n,n]\n",
        "  cov  : [q,q]\n",
        "  sample_size : scalar\n",
        "  \"\"\"\n",
        "  data = log_normal_sampling(mean,cov,sample_size)\n",
        "  return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPjKvc8k7iSy"
      },
      "source": [
        "**Recursive Karcher Expectation Estimator (RKEE)**\n",
        "\n",
        "RKEE is based on simple but elegant observation obtained by looking at online estimator of Euclidean Mean. Given $N$ i.i.d samples from euclidean random variable then empirical mean is $\\displaystyle S_{N} = \\frac{X_1 + \\dots + X_N}{N}$. Then equivalent way to compute is by recursive estimator \n",
        "\n",
        "\n",
        "$$ S_{k+1} = \\begin{cases} \n",
        "      X_1 & k=0 \\\\\n",
        "       \\dfrac{k}{k+1}.S_{k} + \\dfrac{1}{k+1}X_{k+1} & k \\leq N-1  &\n",
        "   \\end{cases}\n",
        "$$\n",
        "\n",
        "Mean for $k+1$ is seen as moving from current mean (with weight $\\frac{k}{k+1}$) to new point (with weight $\\frac{1}{k+1}$). But on Manifold there is no notion of addition, so we cannot move along a straight line. Instead we can move along geodesics. Under affinte Invariant Metric, Given $N,M \\in \\text{Sym}_{+}^{n}$ there is a unique geodesic joining $N,M$ given by $\\gamma(s) = \\text{M}_{k}^{\\frac{1}{2}}\\left[\\text{M}_{k}^{-\\frac{1}{2}}\\text{X}_{k+1}\\text{M}_{k}^{-\\frac{1}{2}} \\right]^{s}\\text{M}_{k}^{\\frac{1}{2}}$. This is the key observations that is used in deriving the recursive estimator\n",
        "\n",
        "$$\\begin{align*} \\text{M}_{1} &= \\text{X}_{1} \\\\\n",
        "\\text{M}_{k} &= \\text{M}_{k}^{\\frac{1}{2}}\\left[\\text{M}_{k}^{-\\frac{1}{2}}\\text{X}_{k+1}\\text{M}_{k}^{-\\frac{1}{2}} \\right]^{\\frac{1}{k+1}}\\text{M}_{k}^{\\frac{1}{2}}\n",
        " \\end{align*}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "27mFE1d-7D-2"
      },
      "source": [
        "def RKEE(data):\n",
        "  \"\"\"\n",
        "  data : [p,n,n]\n",
        "  Returns :\n",
        "  -------------\n",
        "  Karcher mean wrt to GL invariant metric\n",
        "  \"\"\"\n",
        "\n",
        "  M_current = data[0]\n",
        "  list_of_means = [M_current]\n",
        "  for k in range(1,data.shape[0]):\n",
        "    X_k       = data[k]\n",
        "    M_hf      = fractional_matrix_power(M_current,0.5)\n",
        "    M_nhf     = fractional_matrix_power(M_current,-0.5)\n",
        "    temp      = M_nhf @ X_k @ M_nhf\n",
        "    temp_pow  = fractional_matrix_power(temp,1/(k+1))\n",
        "    M_current = M_hf @ temp_pow @ M_hf\n",
        "    list_of_means.append(M_current)\n",
        "\n",
        "  return list_of_means,M_current\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cafe14HnJpc0"
      },
      "source": [
        "def geomstats_GL_inv_distance(mat1,mat2):\n",
        "  n = mat2.shape[-1]\n",
        "  metric = SPDMetricAffine(n)\n",
        "  dist = metric.dist(mat1,mat2)\n",
        "  return dist"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmqFDPfd6jY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dfbd3dd4-914a-4ac9-e5c2-1e5838b41319"
      },
      "source": [
        "mean = 3*np.eye(5)\n",
        "cov_shape = (int)((mean.shape[0] * (mean.shape[0]+1) )/2)\n",
        "print(cov_shape)\n",
        "cov  = np.eye(cov_shape)\n",
        "sample_size = 1000\n",
        "data = synthetic_data(mean,cov,sample_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm-pDQBtP46u",
        "outputId": "498bc229-ce51-4988-ae95-16ebca195b46"
      },
      "source": [
        "list_of_means,M_current = RKEE(data)\n",
        "error = geomstats_GL_inv_distance(M_current,mean)\n",
        "print(M_current)\n",
        "print(\"error : \", error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.9666847  -0.01945193  0.00646754 -0.05530743 -0.12516805]\n",
            " [-0.01945193  3.02386065  0.04006943 -0.07610895 -0.0231666 ]\n",
            " [ 0.00646754  0.04006943  2.99867007 -0.05515334 -0.05274952]\n",
            " [-0.05530743 -0.07610895 -0.05515334  3.03845034  0.04606238]\n",
            " [-0.12516805 -0.0231666  -0.05274952  0.04606238  3.01463143]]\n",
            "error :  0.0893841005635958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9t98qFz_MoOM"
      },
      "source": [
        "# #plotting of decreasing error\n",
        "# dist = geomstats_GL_inv_distance(list_of_means,mean)\n",
        "# N = np.arange(1,sample_size+1)\n",
        "# plt.figure(figsize=(8,6))\n",
        "# plt.plot(N,dist)\n",
        "# plt.xlabel(\"N\")\n",
        "# plt.ylabel(\"Error\")\n",
        "# plt.title(\"Decreasing Error of RKEE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErZAjiHxO5Jf"
      },
      "source": [
        "following plot shows reduction of Error as number of samples increases\n",
        "\n",
        "![download (8).png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qe_nYj0ZUEgK"
      },
      "source": [
        "## **Profiling for checking BottleNeck**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HI20uwCr4l3X"
      },
      "source": [
        "#%lprun -f RKEE RKEE(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XTuFJA15PlF"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Timer unit: 1e-06 s\n",
        "\n",
        "**Total time: 22.1974 s**\n",
        "File: <ipython-input-42-dca9a783d75b>\n",
        "Function: RKEE at line 1\n",
        "\n",
        "\n",
        "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
        "```\n",
        "\n",
        "---------------------------------------------------------------------\n",
        "\n",
        "     1                                           def RKEE(data):\n",
        "     2                                             \"\"\"\n",
        "     3                                             data : [p,n,n]\n",
        "     4                                             Returns :\n",
        "     5                                             -------------\n",
        "     6                                             Karcher mean wrt to GL invariant metric\n",
        "     7                                             \"\"\"\n",
        "     8                                           \n",
        "     9         1         62.0     62.0      0.0    M_current = data[0]\n",
        "    10         1          2.0      2.0      0.0    list_of_means = [M_current]\n",
        "    11      1000       1307.0      1.3      0.0    for k in range(1,data.shape[0]):\n",
        "    12       999       2853.0      2.9      0.0      X_k       = data[k]\n",
        "    13       999    7079544.0   7086.6     31.9      M_hf      = fractional_matrix_power(M_current,0.5)\n",
        "    14       999    7126669.0   7133.8     32.1      M_nhf     = fractional_matrix_power(M_current,-0.5)\n",
        "    15       999      15506.0     15.5      0.1      temp      = M_nhf @ X_k @ M_nhf\n",
        "    16       999    7952443.0   7960.4     35.8      temp_pow  = fractional_matrix_power(temp,1/k)\n",
        "    17       999      16745.0     16.8      0.1      M_current = M_hf @ temp_pow @ M_hf\n",
        "    18       999       2306.0      2.3      0.0      list_of_means.append(M_current)\n",
        "    19                                           \n",
        "    20         1          2.0      2.0      0.0    return list_of_means,M_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THWUT9S94Xfe"
      },
      "source": [
        "## **Speeding up the computation of RKEE**\n",
        "\n",
        "\n",
        "As can be seen most of the time is spent at computing fractional powers. To speed up,  computation of power is done by diagonlization, as SPD matrices are inddeed diagonalizable this is valid. \n",
        "\n",
        "$$\\text{X} = UDU^{T} \\implies X^{a} = UD^{a}U^{T} $$ \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dly8f6xH4Xfi"
      },
      "source": [
        "def frac_pow_egdec(mat,pow):\n",
        "  e_val , e_vec  = gs.linalg.eigh(mat)\n",
        "  e_val_pow      = e_val ** pow\n",
        "  diag           = np.diag(e_val_pow)\n",
        "  pow            =  e_vec @ diag @ e_vec.T\n",
        "  return pow"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6K3N7Kh7zN8"
      },
      "source": [
        "def RKEE_opt1(data):\n",
        "  \"\"\"\n",
        "  data : [p,n,n]\n",
        "  Returns :\n",
        "  -------------\n",
        "  Karcher mean wrt to GL invariant metric\n",
        "  \"\"\"\n",
        "\n",
        "  M_current = data[0]\n",
        "  list_of_means = [M_current]\n",
        "  for k in range(1,data.shape[0]):\n",
        "    X_k       = data[k]\n",
        "    M_hf      = frac_pow_egdec(M_current,0.5)\n",
        "    M_nhf     = frac_pow_egdec(M_current,-0.5)\n",
        "    temp      = M_nhf @ X_k @ M_nhf\n",
        "    temp_pow  = frac_pow_egdec(temp,1/(k+1))\n",
        "    M_current = M_hf @ temp_pow @ M_hf\n",
        "    list_of_means.append(M_current)\n",
        "\n",
        "  return list_of_means,M_current\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqRJwVt5FK6u",
        "outputId": "88b7315c-7eb3-4e7f-9174-ef699ede97e2"
      },
      "source": [
        "list_of_means,M_current = RKEE_opt1(data)\n",
        "error = geomstats_GL_inv_distance(M_current,mean)\n",
        "print(M_current)\n",
        "print(\"error : \", error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.9666847  -0.01945193  0.00646754 -0.05530743 -0.12516805]\n",
            " [-0.01945193  3.02386065  0.04006943 -0.07610895 -0.0231666 ]\n",
            " [ 0.00646754  0.04006943  2.99867007 -0.05515334 -0.05274952]\n",
            " [-0.05530743 -0.07610895 -0.05515334  3.03845034  0.04606238]\n",
            " [-0.12516805 -0.0231666  -0.05274952  0.04606238  3.01463143]]\n",
            "error :  0.08938410056366876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4PqP6KrW7-7E"
      },
      "source": [
        "#%lprun -f RKEE_opt1 RKEE_opt1(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPbCewLf8Q_3"
      },
      "source": [
        "\n",
        "\n",
        "```\n",
        "Timer unit: 1e-06 s\n",
        "\n",
        "Total time: 0.205232 s\n",
        "File: <ipython-input-113-e9df60f3c43e>\n",
        "Function: RKEE_opt1 at line 1\n",
        "\n",
        "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
        "```\n",
        "-----------------------------------------------------------------------\n",
        "     1                                           def RKEE_opt1(data):\n",
        "     2                                             \"\"\"\n",
        "     3                                             data : [p,n,n]\n",
        "     4                                             Returns :\n",
        "     5                                             -------------\n",
        "     6                                             Karcher mean wrt to GL invariant metric\n",
        "     7                                             \"\"\"\n",
        "     8                                           \n",
        "     9         1         79.0     79.0      0.0    M_current = data[0]\n",
        "    10         1          2.0      2.0      0.0    list_of_means = [M_current]\n",
        "    11      1000        697.0      0.7      0.3    for k in range(1,data.shape[0]):\n",
        "    12       999       1155.0      1.2      0.6      X_k       = data[k]\n",
        "    13       999      65571.0     65.6     31.9      M_hf      = frac_pow_egdec(M_current,0.5)\n",
        "    14       999      64162.0     64.2     31.3      M_nhf     = frac_pow_egdec(M_current,-0.5)\n",
        "    15       999       4749.0      4.8      2.3      temp      = M_nhf @ X_k @ M_nhf\n",
        "    16       999      63153.0     63.2     30.8      temp_pow  = frac_pow_egdec(temp,1/k)\n",
        "    17       999       4744.0      4.7      2.3      M_current = M_hf @ temp_pow @ M_hf\n",
        "    18       999        919.0      0.9      0.4      list_of_means.append(M_current)\n",
        "    19                                           \n",
        "    20         1          1.0      1.0      0.0    return list_of_means,M_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9H195NMxAn9e"
      },
      "source": [
        "We can improve performance further by using observation that $M^{\\frac{1}{2}}$ and $M^{-\\frac{1}{2}}$ can be computed jointly because the matrix eigendecomposition will be same and hence we can compute it only once and carryout  the rest of computation exactly same. Note that `scipy`, `numpy` or `geomstats` don't provide such  kind of function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BXdck6HL4Xfj"
      },
      "source": [
        "def batch_frac_pow_egdec(mat,pows):\n",
        "  e_val , e_vec  = gs.linalg.eigh(mat)\n",
        "  powers = []\n",
        "  for p in pows:\n",
        "    e_val_pow = e_val ** p\n",
        "    diag      = np.diag(e_val_pow)\n",
        "    power       =  e_vec @ diag @ e_vec.T\n",
        "    powers.append(power)\n",
        "  return powers  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiUDwbw281HO"
      },
      "source": [
        "def RKEE_opt2(data):\n",
        "  \"\"\"\n",
        "  data : [p,n,n]\n",
        "  Returns :\n",
        "  -------------\n",
        "  Karcher mean wrt to GL invariant metric\n",
        "  \"\"\"\n",
        "\n",
        "  M_current = data[0]\n",
        "  list_of_means = [M_current]\n",
        "  for k in range(1,data.shape[0]):\n",
        "    X_k             = data[k]\n",
        "    M_hf,M_nhf      = batch_frac_pow_egdec(M_current,[0.5,-0.5])\n",
        "    temp            = M_nhf @ X_k @ M_nhf\n",
        "    temp_pow        = batch_frac_pow_egdec(temp,[1/(k+1)])[0]\n",
        "    M_current       = M_hf @ temp_pow @ M_hf\n",
        "    list_of_means.append(M_current)\n",
        "\n",
        "  return list_of_means,M_current\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6M1UM4c1CsDn",
        "outputId": "d62a5979-6d20-4890-945a-10a1adb95fdd"
      },
      "source": [
        "list_of_means,M_current = RKEE_opt2(data)\n",
        "error = geomstats_GL_inv_distance(M_current,mean)\n",
        "print(M_current)\n",
        "print(\"error : \", error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 2.9666847  -0.01945193  0.00646754 -0.05530743 -0.12516805]\n",
            " [-0.01945193  3.02386065  0.04006943 -0.07610895 -0.0231666 ]\n",
            " [ 0.00646754  0.04006943  2.99867007 -0.05515334 -0.05274952]\n",
            " [-0.05530743 -0.07610895 -0.05515334  3.03845034  0.04606238]\n",
            " [-0.12516805 -0.0231666  -0.05274952  0.04606238  3.01463143]]\n",
            "error :  0.08938410056366876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qaC_T4S99PTW"
      },
      "source": [
        "%lprun -f RKEE_opt2 RKEE_opt2(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koHe8FKu-NaF"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "Timer unit: 1e-06 s\n",
        "\n",
        "Total time: 0.154766 s\n",
        "File: <ipython-input-116-bc1ce2a4e206>\n",
        "Function: RKEE_opt2 at line 1\n",
        "\n",
        "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
        "```\n",
        "---------------------------------------------------------------------\n",
        "     1                                           def RKEE_opt2(data):\n",
        "     2                                             \"\"\"\n",
        "     3                                             data : [p,n,n]\n",
        "     4                                             Returns :\n",
        "     5                                             -------------\n",
        "     6                                             Karcher mean wrt to GL invariant metric\n",
        "     7                                             \"\"\"\n",
        "     8                                           \n",
        "     9         1          8.0      8.0      0.0    M_current = data[0]\n",
        "    10         1          1.0      1.0      0.0    list_of_means = [M_current]\n",
        "    11      1000        717.0      0.7      0.5    for k in range(1,data.shape[0]):\n",
        "    12       999       1096.0      1.1      0.7      X_k             = data[k]\n",
        "    13       999      76836.0     76.9     49.6      M_hf,M_nhf      = batch_frac_pow_egdec(M_current,[0.5,-0.5])\n",
        "    14       999       4844.0      4.8      3.1      temp            = M_nhf @ X_k @ M_nhf\n",
        "    15       999      65463.0     65.5     42.3      temp_pow        = frac_pow_egdec(temp,1/k)\n",
        "    16       999       4840.0      4.8      3.1      M_current       = M_hf @ temp_pow @ M_hf\n",
        "    17       999        961.0      1.0      0.6      list_of_means.append(M_current)\n",
        "    18                                           \n",
        "    19         1          0.0      0.0      0.0    return list_of_means,M_current"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zdkapAt-rGZ"
      },
      "source": [
        "As can be seen for **n=1000**\n",
        "\n",
        "Time for RKEE      : **22.1974 s**\n",
        "\n",
        "Time for RKEE_opt1 : **0.205232 s**\n",
        "\n",
        "Time for RKEE_opt2 : **0.154766 s**\n",
        "\n",
        "Hence the Improvement achieved is **108X**  with first optimization and with second optimization **144X**.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pubPhEf1HORK"
      },
      "source": [
        "$\\log(X^{-1}Y) = -\\log(X) + \\log(Y)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XbKSU55krm7"
      },
      "source": [
        "def GL_invariant_metric(spd_1,spd_2):\n",
        "  \"\"\"\n",
        "    spd_1 : np array\n",
        "    spd_2 : np array\n",
        "  \"\"\"\n",
        "\n",
        "  log_prod = logm(spd_2)-logm(spd_1)\n",
        "  if log_prod.ndim == 2:\n",
        "    dist     =  np.einsum('ij,ji->', log_prod, log_prod)\n",
        "  elif log_prod.ndim == 3:\n",
        "    dist     =  np.einsum('ijk,ikj->i', log_prod, log_prod) \n",
        "  return dist**0.5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tvt5JLeeQeRU"
      },
      "source": [
        "array_of_means = np.array(list_of_means)\n",
        "error = GL_invariant_metric(array_of_means,mean)\n",
        "print(\"error\" , error)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFRCoUf7RPWT"
      },
      "source": [
        "#%lprun -f geomstats_GL_inv_distance geomstats_GL_inv_distance(array_of_means,mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVrPZhUiQMxG"
      },
      "source": [
        "#%lprun -f GL_invariant_metric GL_invariant_metric(array_of_means,mean)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JvW6KmcomC2"
      },
      "source": [
        "#tell them that GL_invariant metric should be computed in easiest way"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-3HP55GJAHQ"
      },
      "source": [
        "Building **Efficient K-means**(for GL-invariant metric) with Recursive Karcher Expectation Estimator.\n",
        "\n",
        "With RKEE, we can efficintely update (add and remove) the mean\n",
        "\n",
        "broad idea of **Efficient-K-means:**\n",
        "\n",
        "\n",
        "*   Let there be K clusters\n",
        "*   Let there $X_i$ be points in ith iteration whose clusters have changed\n",
        "*   for $x_i \\in X_i$:\n",
        "\n",
        "$\\hspace{1cm} \\text{Let S be previous cluster of }  x_i$\n",
        "\n",
        "$\\hspace{1cm} \\text{Let T be current cluster of }   x_i$\n",
        "\n",
        "$\\hspace{1cm} \\text{new mean of S} = \\text{SUBTRACT}\\text{(current mean of S,x_i)}  $\n",
        "\n",
        "$\\hspace{1cm} \\text{new mean of T} = \\text{ADD}\\text{(current mean of T, x_i)}$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xg1hGYQXATWT"
      },
      "source": [
        "def generate_data(means,samples_per_mean):\n",
        "  \"\"\"\n",
        "  means    : [N,n,n]\n",
        "  ----------------\n",
        "  Returns  :\n",
        "\n",
        "  \"\"\"\n",
        "  n = means.shape[1]\n",
        "  p = (int)((n*(n+1))/2)\n",
        "  cov = np.eye(p)/p\n",
        "  total_data = []\n",
        "  labels = []\n",
        "  for i,mean in enumerate(means):\n",
        "    data = log_normal_sampling(mean,cov,samples_per_mean)\n",
        "    total_data.append(data)\n",
        "    labels.append(np.array([i] * samples_per_mean ))\n",
        "  total_data = np.vstack(total_data)\n",
        "  labels = np.hstack(labels)\n",
        "  return total_data,labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic43lzelFUMy"
      },
      "source": [
        "def get_data(dim=5,num_clusters=7,samples_per_mean=200):\n",
        "  base = np.eye(dim)\n",
        "  mul  = np.random.uniform(0,3*num_clusters,num_clusters)\n",
        "  cluster_centers = np.array([m*base for m in mul ])\n",
        "  data,labels = generate_data(cluster_centers,samples_per_mean)\n",
        "  idx = np.random.permutation(len(data))\n",
        "  x,y = data[idx], labels[idx]\n",
        "  return x,y,cluster_centers\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bXQg2apNJOI"
      },
      "source": [
        "\"\"\"K-means clustering.\"\"\"\n",
        "\n",
        "import logging\n",
        "from random import randint\n",
        "from sklearn.base import BaseEstimator, ClusterMixin\n",
        "import geomstats.backend as gs\n",
        "from geomstats.learning._template import TransformerMixin\n",
        "from geomstats.learning.frechet_mean import FrechetMean\n",
        "\n",
        "\n",
        "class EfficientKMeans(TransformerMixin, ClusterMixin, BaseEstimator):\n",
        "    \"\"\"Class for k-means clustering on manifolds.\n",
        "    K-means algorithm using Riemannian manifolds.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_clusters : int\n",
        "        Number of clusters (k value of the k-means).\n",
        "        Optional, default: 8.\n",
        "    init : str\n",
        "        How to initialize centroids at the beginning of the algorithm. The\n",
        "        choice 'random' will select training points as initial centroids\n",
        "        uniformly at random.\n",
        "        Optional, default: 'random'.\n",
        "    tol : float\n",
        "        Convergence factor. Convergence is achieved when the difference of mean\n",
        "        distance between two steps is lower than tol.\n",
        "        Optional, default: 1e-2.\n",
        "    verbose : int\n",
        "        If verbose > 0, information will be printed during learning.\n",
        "        Optional, default: 0.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, metric, n_clusters=8, init='random',tol=1e-2, verbose=0):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.init = init\n",
        "        self.metric = metric\n",
        "        self.tol = tol\n",
        "        self.verbose = verbose\n",
        "\n",
        "        self.centroids = None\n",
        "        self.belongs   = None\n",
        "\n",
        "    def fit(self, X, max_iter=100):\n",
        "        \"\"\"Provide clusters centroids and data labels.\n",
        "        Alternate between computing the mean of each cluster\n",
        "        and labelling data according to the new positions of the centroids.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape=[..., n_features]\n",
        "            Training data, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        max_iter : int\n",
        "            Maximum number of iterations.\n",
        "            Optional, default: 100.\n",
        "        Returns\n",
        "        -------\n",
        "        self : array-like, shape=[n_clusters,]\n",
        "            Centroids.\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        self.centroids = [gs.expand_dims(X[randint(0, n_samples - 1)], 0)\n",
        "                          for i in range(self.n_clusters)]\n",
        "        self.centroids = gs.concatenate(self.centroids, axis=0)\n",
        "        index = 0\n",
        "\n",
        "        while index < max_iter:\n",
        "            \n",
        "            index += 1\n",
        "            dists = [gs.to_ndarray(\n",
        "                     self.metric.dist(self.centroids[i], X), 2, 1)\n",
        "                     for i in range(self.n_clusters)]\n",
        "            dists = gs.hstack(dists)\n",
        "            belongs = gs.argmin(dists, 1)\n",
        "            if (index > 1):\n",
        "                old_belongs  = gs.copy(self.belongs)\n",
        "                self.belongs = belongs\n",
        "            old_centroids = gs.copy(self.centroids)\n",
        "            for i in range(self.n_clusters):\n",
        "                fold = gs.squeeze(X[belongs == i])\n",
        "                if len(fold) > 0:\n",
        "\n",
        "                    if (index == 1) :\n",
        "                        self.centroids[i] = self.compute_mean(fold)\n",
        "                        self.belongs = belongs\n",
        "                        \n",
        "                    else :\n",
        "                        old = old_belongs == i\n",
        "                        new = self.belongs == i\n",
        "                        previous_total = np.sum(old)\n",
        "                        add =  X[ np.logical_and(new,np.invert(old)) ]\n",
        "                        sub =  X[ np.logical_and(old,np.invert(new)) ]\n",
        "                        \n",
        "                        if (np.sum(new) != np.sum(old)- sub.shape[0] + add.shape[0]):\n",
        "                          print(\"!!!!!!!!Error!!!!!!!\")\n",
        "                        self.centroids[i] = self.update_centroid(old_centroids[i],add,sub,previous_total)\n",
        "\n",
        "                else:\n",
        "                    self.centroids[i] = X[randint(0, n_samples - 1)]\n",
        "\n",
        "            centroids_distances = self.metric.dist(\n",
        "                old_centroids, self.centroids)\n",
        "\n",
        "            if gs.mean(centroids_distances) < self.tol:\n",
        "                if self.verbose > 0:\n",
        "                    logging.info('Convergence reached after {} '\n",
        "                                 'iterations'.format(index))\n",
        "\n",
        "                if self.n_clusters == 1:\n",
        "                    self.centroids = gs.squeeze(self.centroids, axis=0)\n",
        "\n",
        "                return gs.copy(self.centroids)\n",
        "\n",
        "        if index == max_iter:\n",
        "            logging.warning('K-means maximum number of iterations {} reached. '\n",
        "                            'The mean may be inaccurate'.format(max_iter))\n",
        "\n",
        "        if self.n_clusters == 1:\n",
        "            self.centroids = gs.squeeze(self.centroids, axis=0)\n",
        "        return gs.copy(self.centroids)\n",
        "\n",
        "    def update(self,mean,point,weight):\n",
        "        \"\"\"\n",
        "        mean    : mean of some points\n",
        "        point   : new point\n",
        "        weight  : weight \n",
        "            depending upon the weight (add or removes) point to the mean \n",
        "        \"\"\"\n",
        "\n",
        "          \n",
        "        # M_hf      = fractional_matrix_power(mean,0.5)\n",
        "        # M_nhf     = fractional_matrix_power(mean,-0.5)\n",
        "        # temp      = M_nhf @ point @ M_nhf\n",
        "        # temp_pow  = fractional_matrix_power(temp,weight)\n",
        "        # M_current = M_hf @ temp_pow @ M_hf\n",
        "\n",
        "        M_hf,M_nhf      = batch_frac_pow_egdec(mean,[0.5,-0.5])\n",
        "        temp            = M_nhf @ point @ M_nhf\n",
        "        # manifold = spd.SPDMatrices(temp.shape[-1])\n",
        "        # print(manifold.belongs(temp))\n",
        "        temp_pow        = frac_pow_egdec(temp,weight)\n",
        "        M_current       = M_hf @ temp_pow @ M_hf\n",
        "        return M_current\n",
        "\n",
        " \n",
        "    def compute_mean(self,X):\n",
        "        \"\"\"\n",
        "        X : [N,n,n]\n",
        "        Returns:\n",
        "        -------\n",
        "        mean:[n,n]\n",
        "        \"\"\"\n",
        "        M_current = X[0]\n",
        "        for k in range(1,X.shape[0]):\n",
        "          M_current = self.update(M_current,X[k],1/(k+1))\n",
        "        return M_current\n",
        "\n",
        "\n",
        "    def update_centroid(self,current_centroid,add,sub,curr_N):\n",
        "        \"\"\"\n",
        "        current_centroid : centroid [n,n]\n",
        "        add  : points to be added [a,n,n]\n",
        "        sub  : points to be subtracted [s,n,n]\n",
        "        curr_N : number of points that were used to compute current_centroid\n",
        "        \"\"\"    \n",
        "        \n",
        "        # print(\"curr_N\" , curr_N)\n",
        "        # print(\"add \" , add.shape[0])\n",
        "        # print(\"sub\" , sub.shape[0])\n",
        "        for point in add:\n",
        "            weight = 1/(curr_N+1)\n",
        "            current_centroid = self.update(current_centroid,point,weight)\n",
        "            curr_N = curr_N + 1\n",
        "\n",
        "\n",
        "        for point in sub:\n",
        "            weight = -1/(curr_N-1)\n",
        "            current_centroid = self.update(current_centroid,point,weight)\n",
        "            curr_N = curr_N - 1    \n",
        "        return current_centroid\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for each data point.\n",
        "        Label each data point with the cluster having the nearest\n",
        "        centroid using metric distance.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape=[..., n_features]\n",
        "            Input data.\n",
        "        Returns\n",
        "        -------\n",
        "        self : array-like, shape=[...,]\n",
        "            Array of predicted cluster indices for each sample.\n",
        "        \"\"\"\n",
        "        if self.centroids is None:\n",
        "            raise RuntimeError('fit needs to be called first.')\n",
        "        dists = gs.stack(\n",
        "            [self.metric.dist(centroid, X)\n",
        "             for centroid in self.centroids],\n",
        "            axis=1)\n",
        "        dists = gs.squeeze(dists)\n",
        "        belongs = gs.argmin(dists, -1)\n",
        "        return belongs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoNvIF6_fxxI"
      },
      "source": [
        "import logging\n",
        "from random import randint\n",
        "\n",
        "from sklearn.base import BaseEstimator, ClusterMixin\n",
        "\n",
        "import geomstats.backend as gs\n",
        "from geomstats.learning._template import TransformerMixin\n",
        "from geomstats.learning.frechet_mean import FrechetMean\n",
        "\n",
        "\n",
        "class RiemannianKMeans(TransformerMixin, ClusterMixin, BaseEstimator):\n",
        "    \"\"\"Class for k-means clustering on manifolds.\n",
        "    K-means algorithm using Riemannian manifolds.\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_clusters : int\n",
        "        Number of clusters (k value of the k-means).\n",
        "        Optional, default: 8.\n",
        "    metric : object of class RiemannianMetric\n",
        "        The geomstats Riemmanian metric associate to the space used.\n",
        "    init : str\n",
        "        How to initialize centroids at the beginning of the algorithm. The\n",
        "        choice 'random' will select training points as initial centroids\n",
        "        uniformly at random.\n",
        "        Optional, default: 'random'.\n",
        "    tol : float\n",
        "        Convergence factor. Convergence is achieved when the difference of mean\n",
        "        distance between two steps is lower than tol.\n",
        "        Optional, default: 1e-2.\n",
        "    verbose : int\n",
        "        If verbose > 0, information will be printed during learning.\n",
        "        Optional, default: 0.\n",
        "    Example\n",
        "    -------\n",
        "    Available example on the Poincar Ball and Hypersphere manifolds\n",
        "    :mod:`examples.plot_kmeans_manifolds`\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "            self, metric, n_clusters=8, init='random', lr=5e-3,\n",
        "            tol=1e-2, mean_method='default', verbose=0, point_type='vector'):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.init = init\n",
        "        self.metric = metric\n",
        "        self.tol = tol\n",
        "        self.lr = lr\n",
        "        self.verbose = verbose\n",
        "        self.mean_method = mean_method\n",
        "        self.point_type = point_type\n",
        "\n",
        "        self.centroids = None\n",
        "\n",
        "    def fit(self, X, max_iter=100):\n",
        "        \"\"\"Provide clusters centroids and data labels.\n",
        "        Alternate between computing the mean of each cluster\n",
        "        and labelling data according to the new positions of the centroids.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape=[..., n_features]\n",
        "            Training data, where n_samples is the number of samples and\n",
        "            n_features is the number of features.\n",
        "        max_iter : int\n",
        "            Maximum number of iterations.\n",
        "            Optional, default: 100.\n",
        "        Returns\n",
        "        -------\n",
        "        self : array-like, shape=[n_clusters,]\n",
        "            Centroids.\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        self.centroids = [gs.expand_dims(X[randint(0, n_samples - 1)], 0)\n",
        "                          for i in range(self.n_clusters)]\n",
        "        self.centroids = gs.concatenate(self.centroids, axis=0)\n",
        "        index = 0\n",
        "        while index < max_iter:\n",
        "            index += 1\n",
        "\n",
        "            dists = [gs.to_ndarray(\n",
        "                     self.metric.dist(self.centroids[i], X), 2, 1)\n",
        "                     for i in range(self.n_clusters)]\n",
        "            dists = gs.hstack(dists)\n",
        "            belongs = gs.argmin(dists, 1)\n",
        "            old_centroids = gs.copy(self.centroids)\n",
        "            for i in range(self.n_clusters):\n",
        "                fold = gs.squeeze(X[belongs == i])\n",
        "                \n",
        "\n",
        "                if len(fold) > 0:\n",
        "\n",
        "                    mean = FrechetMean(\n",
        "                        metric=self.metric,\n",
        "                        method=self.mean_method,\n",
        "                        max_iter=150,\n",
        "                        lr=self.lr,\n",
        "                        point_type=self.point_type)\n",
        "                    mean.fit(fold)\n",
        "\n",
        "                    self.centroids[i] = mean.estimate_\n",
        "                else:\n",
        "                    self.centroids[i] = X[randint(0, n_samples - 1)]\n",
        "\n",
        "            centroids_distances = self.metric.dist(\n",
        "                old_centroids, self.centroids)\n",
        "\n",
        "            if gs.mean(centroids_distances) < self.tol:\n",
        "                if self.verbose > 0:\n",
        "                    logging.info('Convergence reached after {} '\n",
        "                                 'iterations'.format(index))\n",
        "\n",
        "                if self.n_clusters == 1:\n",
        "                    self.centroids = gs.squeeze(self.centroids, axis=0)\n",
        "\n",
        "                return gs.copy(self.centroids)\n",
        "\n",
        "        if index == max_iter:\n",
        "            logging.warning('K-means maximum number of iterations {} reached. '\n",
        "                            'The mean may be inaccurate'.format(max_iter))\n",
        "\n",
        "        if self.n_clusters == 1:\n",
        "            self.centroids = gs.squeeze(self.centroids, axis=0)\n",
        "        return gs.copy(self.centroids)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Predict the labels for each data point.\n",
        "        Label each data point with the cluster having the nearest\n",
        "        centroid using metric distance.\n",
        "        Parameters\n",
        "        ----------\n",
        "        X : array-like, shape=[..., n_features]\n",
        "            Input data.\n",
        "        Returns\n",
        "        -------\n",
        "        self : array-like, shape=[...,]\n",
        "            Array of predicted cluster indices for each sample.\n",
        "        \"\"\"\n",
        "        if self.centroids is None:\n",
        "            raise RuntimeError('fit needs to be called first.')\n",
        "        dists = gs.stack(\n",
        "            [self.metric.dist(centroid, X)\n",
        "             for centroid in self.centroids],\n",
        "            axis=1)\n",
        "        dists = gs.squeeze(dists)\n",
        "\n",
        "        belongs = gs.argmin(dists, -1)\n",
        "\n",
        "        return belongs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZzNCHoR90mrT"
      },
      "source": [
        "def get_error(true,pred,metric):\n",
        "  dist = metric.dist(true,pred)\n",
        "  error = gs.mean(dist)\n",
        "  return error"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTB7liyxl0mO",
        "outputId": "42d80c08-3144-446a-ed85-bbaad8a05ad8"
      },
      "source": [
        "X,y,cluster_centers = get_data(num_clusters = 8,samples_per_mean=1000)\n",
        "true_centers = cluster_centers[y]\n",
        "n = X.shape[1]\n",
        "print(\"data\" , X.shape)\n",
        "print(\"labels\" , y.shape)\n",
        "metric = SPDMetricAffine(n)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data (8000, 5, 5)\n",
            "labels (8000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KmvZScRRbaU-",
        "outputId": "ebc76e8d-e3ad-4eb0-bcb4-ca29b6313bd3"
      },
      "source": [
        "# kmeans = RiemannianKMeans(metric, 8, tol=1e-3 ,point_type='matrix' , verbose=1)\n",
        "# kmeans.fit(X)\n",
        "# pred_labels  = kmeans.predict(X)\n",
        "# centroids = kmeans.centroids\n",
        "# pred_centers = centroids[pred_labels]\n",
        "# error = get_error(true_centers,pred_centers,metric)\n",
        "# print(\"ERROR is \", error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: K-means maximum number of iterations 100 reached. The mean may be inaccurate\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR is  0.21538469238142374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXxru2Ey7Ub8",
        "outputId": "0a7995c3-eaec-4eaf-f514-77e6178594e8"
      },
      "source": [
        "%lprun -f kmeans.fit kmeans.fit(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Convergence reached after 55 iterations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPc56wr7nKO4",
        "outputId": "7b58a293-c569-40b5-ab14-2ab04f450ae4"
      },
      "source": [
        "# kmeans = EfficientKMeans(metric, 8, tol=1e-3,verbose=1)\n",
        "# kmeans.fit(X)\n",
        "# pred_labels  = kmeans.predict(X)\n",
        "# centroids = kmeans.centroids\n",
        "# pred_centers = centroids[pred_labels]\n",
        "# error = get_error(true_centers,pred_centers,metric)\n",
        "# print(\"ERROR is \", error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Convergence reached after 69 iterations\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ERROR is  0.1969293469135379\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrX4L4N46MQJ",
        "outputId": "170cbbc2-6817-4124-9a7b-f77ec9a4d41d"
      },
      "source": [
        "%lprun -f kmeans.fit kmeans.fit(X)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO: Convergence reached after 63 iterations\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMZfa5HIkOA0"
      },
      "source": [
        "def add (M, X, k):\n",
        "  M_hf      = fractional_matrix_power(M,0.5)\n",
        "  M_nhf     = fractional_matrix_power(M,-0.5)\n",
        "  temp      = M_nhf @ X @ M_nhf\n",
        "  temp_pow  = fractional_matrix_power(temp,1/(k+1))\n",
        "  M_current = M_hf @ temp_pow @ M_hf\n",
        "  return M_current"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEK9umgCk3vE"
      },
      "source": [
        "def subtract(M, X, k):\n",
        "  M_hf      = fractional_matrix_power(M,0.5)\n",
        "  M_nhf     = fractional_matrix_power(M,-0.5)\n",
        "  temp      = M_nhf @ X @ M_nhf\n",
        "  temp_pow  = fractional_matrix_power(temp,-1/(k-1))\n",
        "  M_current = M_hf @ temp_pow @ M_hf\n",
        "  return M_current\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}